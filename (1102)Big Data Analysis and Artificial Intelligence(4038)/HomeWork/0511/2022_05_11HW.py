# -*- coding: utf-8 -*-
"""2022-05-11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PCE-j0ja-ppxC-r2TSfk5_LzkenJJDWL
"""

# import numpy as np
# from tensorflow.keras.datasets import reuters
# from tensorflow.keras.preprocessing import sequence
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import Dense, Embedding, Dropout, Flatten
# from tensorflow.keras.utils import to_categorical

# seed = 10
# np.random.seed(seed)  # 指定亂數種子
# # 載入Reuters資料集
# top_words = 10000
# (X_train, Y_train), (X_test, Y_test) = reuters.load_data(
#                                        num_words=top_words)
# # 資料預處理
# max_words = 200 
# X_train = sequence.pad_sequences(X_train, maxlen=max_words)
# X_test = sequence.pad_sequences(X_test, maxlen=max_words)
# # One-hot編碼
# Y_train = to_categorical(Y_train, 46)
# Y_test = to_categorical(Y_test, 46)
# # 定義模型
# model = Sequential()
# model.add(Embedding(top_words, 32, input_length=max_words))
# model.add(Dropout(0.75))
# model.add(Flatten())
# model.add(Dense(64, activation="relu"))
# model.add(Dropout(0.25))
# model.add(Dense(64, activation="relu"))
# model.add(Dropout(0.25))
# model.add(Dense(46, activation="softmax"))
# model.summary()   # 顯示模型摘要資訊
# # 編譯模型
# model.compile(loss="categorical_crossentropy", optimizer="adam", 
#               metrics=["accuracy"])
# # 訓練模型
# history = model.fit(X_train, Y_train, validation_split=0.2, 
#           epochs=50, batch_size=32, verbose=2)
# # 評估模型
# loss, accuracy = model.evaluate(X_test, Y_test)
# print("測試資料集的準確度 = {:.2f}".format(accuracy))
# # 顯示訓練和驗證損失圖表
# import matplotlib.pyplot as plt

# loss = history.history["loss"]
# epochs = range(1, len(loss)+1)
# val_loss = history.history["val_loss"]
# plt.plot(epochs, loss, "bo", label="Training Loss")
# plt.plot(epochs, val_loss, "r", label="Validation Loss")
# plt.title("Training and Validation Loss")
# plt.xlabel("Epochs")
# plt.ylabel("Loss")
# plt.legend()
# plt.show()
# # 顯示訓練和驗證準確度
# acc = history.history["accuracy"]
# epochs = range(1, len(acc)+1)
# val_acc = history.history["val_accuracy"]
# plt.plot(epochs, acc, "b-", label="Training Acc")
# plt.plot(epochs, val_acc, "r--", label="Validation Acc")
# plt.title("Training and Validation Accuracy")
# plt.xlabel("Epochs")
# plt.ylabel("Accuracy")
# plt.legend()
# plt.show()

# import numpy as np
# from tensorflow.keras.datasets import reuters
# from tensorflow.keras.preprocessing import sequence
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import Embedding, Dropout, LSTM, Dense
# from tensorflow.keras.utils import to_categorical

# seed = 10
# np.random.seed(seed)  # 指定亂數種子
# # 載入Reuters資料集
# top_words = 10000
# (X_train, Y_train), (X_test, Y_test) = reuters.load_data(num_words=top_words)
# # 資料預處理
# max_words = 200 
# X_train = sequence.pad_sequences(X_train, maxlen=max_words)
# X_test = sequence.pad_sequences(X_test, maxlen=max_words)
# # One-hot編碼
# Y_train = to_categorical(Y_train, 46)
# Y_test = to_categorical(Y_test, 46)
# # 定義模型
# model = Sequential()
# model.add(Embedding(top_words, 32, input_length=max_words))
# model.add(Dropout(0.75))
# model.add(LSTM(32, return_sequences=True))
# model.add(LSTM(32))
# model.add(Dropout(0.5))
# model.add(Dense(46, activation="softmax"))
# model.summary()   # 顯示模型摘要資訊
# # 編譯模型
# model.compile(loss="categorical_crossentropy", optimizer="rmsprop", 
#               metrics=["accuracy"])
# # 訓練模型
# history = model.fit(X_train, Y_train, validation_split=0.2, 
#                     epochs=50, batch_size=32, verbose=2)
# # 評估模型
# loss, accuracy = model.evaluate(X_test, Y_test)
# print("測試資料集的準確度 = {:.2f}".format(accuracy))
# # 顯示訓練和驗證損失圖表
# import matplotlib.pyplot as plt

# loss = history.history["loss"]
# epochs = range(1, len(loss)+1)
# val_loss = history.history["val_loss"]
# plt.plot(epochs, loss, "bo", label="Training Loss")
# plt.plot(epochs, val_loss, "r", label="Validation Loss")
# plt.title("Training and Validation Loss")
# plt.xlabel("Epochs")
# plt.ylabel("Loss")
# plt.legend()
# plt.show()
# # 顯示訓練和驗證準確度
# acc = history.history["accuracy"]
# epochs = range(1, len(acc)+1)
# val_acc = history.history["val_accuracy"]
# plt.plot(epochs, acc, "b-", label="Training Acc")
# plt.plot(epochs, val_acc, "r--", label="Validation Acc")
# plt.title("Training and Validation Accuracy")
# plt.xlabel("Epochs")
# plt.ylabel("Accuracy")
# plt.legend()
# plt.show()

# !wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz
# !tar -zxf aclImdb_v1.tar.gz

import numpy as np
import re
from os import listdir
from keras.preprocessing import sequence
from keras.preprocessing.text import Tokenizer

# IMDb資料所在目錄
path = "/content/aclImdb/"
# 建立檔案清單
fList = [path + "train/pos/" + x for x in listdir(path + "train/pos")] + \
        [path + "train/neg/" + x for x in listdir(path + "train/neg")] + \
        [path + "test/pos/" + x for x in listdir(path + "test/pos")] + \
        [path + "test/neg/" + x for x in listdir(path + "test/neg")]

# 刪除HTML標籤的符號
def remove_tags(text):
    TAG = re.compile(r'<[^>]+>')
    return TAG.sub('', text)
# 讀取文字檔案的資料    
input_label = ([1] * 12500 + [0] * 12500) * 2
input_text  = []
# 讀取檔案內容
for fname in fList:
    with open(fname, encoding="utf8") as ff:
        input_text += [remove_tags(" ".join(ff.readlines()))]
print(input_text[5])
print(input_label[5])
# 將文件分割成單字, 建立詞索引字典       
tok = Tokenizer(num_words=2000)
tok.fit_on_texts(input_text[:25000])
print("文件數: ", tok.document_count)
print({k: tok.word_index[k] for k in list(tok.word_index)[:10]})
# 建立訓練和測試資料集
X_train = tok.texts_to_sequences(input_text[:25000])
X_test  = tok.texts_to_sequences(input_text[25000:])
Y_train = input_label[:25000]
Y_test  = input_label[25000:]
# 將序列資料填充成相同長度
X_train = sequence.pad_sequences(X_train, maxlen=100)
X_test  = sequence.pad_sequences(X_test,  maxlen=100)
X_train = np.array(X_train)
X_test = np.array(X_test)
Y_train = np.array(Y_train)
Y_test = np.array(Y_test)
print("X_train.shape: ", X_train.shape)
print("X_test.shape: ", X_test.shape)

from keras.datasets import imdb
from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers import Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM
import matplotlib.pyplot as plt

# 定義模型
model = Sequential()
model.add(Embedding(1000, 32, input_length=100))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(256, activation="relu"))
model.add(Dropout(0.25))
model.add(Dense(1, activation="sigmoid"))
model.summary()   # 顯示模型摘要資訊
# 編譯模型
model.compile(loss="binary_crossentropy", optimizer="adam", 
              metrics=["accuracy"])
# 訓練模型
history = model.fit(X_train, Y_train, validation_split=0.2, epochs=20, batch_size=128, verbose=0)
# 評估模型
loss, accuracy = model.evaluate(X_test, Y_test)
print("測試資料集的準確度 = {:.2f}".format(accuracy))

# 顯示訓練和驗證損失圖表
loss = history.history["loss"]
epochs = range(1, len(loss)+1)
val_loss = history.history["val_loss"]
plt.plot(epochs, loss, "bo", label="Training Loss")
plt.plot(epochs, val_loss, "r", label="Validation Loss")
plt.title("Training and Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()
# 顯示訓練和驗證準確度
acc = history.history["accuracy"]
epochs = range(1, len(acc)+1)
val_acc = history.history["val_accuracy"]
plt.plot(epochs, acc, "b-", label="Training Acc")
plt.plot(epochs, val_acc, "r--", label="Validation Acc")
plt.title("Training and Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

# 資料預處理
max_words = 100
X_train = sequence.pad_sequences(X_train, maxlen=max_words)
X_test = sequence.pad_sequences(X_test, maxlen=max_words)
# 定義模型
model = Sequential()
model.add(Embedding(1000, 32, input_length=100))
model.add(Dropout(0.25))
model.add(Conv1D(filters=32, kernel_size=3, padding="same",
                 activation="relu"))
model.add(MaxPooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(256, activation="relu"))
model.add(Dropout(0.25))
model.add(Dense(1, activation="sigmoid"))
model.summary()   # 顯示模型摘要資訊
# 編譯模型
model.compile(loss="binary_crossentropy", optimizer="adam", 
              metrics=["accuracy"])
# 訓練模型
history = model.fit(X_train, Y_train, validation_split=0.2, epochs=20, batch_size=128, verbose=0)
# 評估模型
loss, accuracy = model.evaluate(X_test, Y_test)
print("測試資料集的準確度 = {:.2f}".format(accuracy))

# 顯示訓練和驗證損失圖表
loss = history.history["loss"]
epochs = range(1, len(loss)+1)
val_loss = history.history["val_loss"]
plt.plot(epochs, loss, "bo", label="Training Loss")
plt.plot(epochs, val_loss, "r", label="Validation Loss")
plt.title("Training and Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()
# 顯示訓練和驗證準確度
acc = history.history["accuracy"]
epochs = range(1, len(acc)+1)
val_acc = history.history["val_accuracy"]
plt.plot(epochs, acc, "b-", label="Training Acc")
plt.plot(epochs, val_acc, "r--", label="Validation Acc")
plt.title("Training and Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

# 定義模型
model = Sequential()
model.add(Embedding(1000, 32, input_length=100))
model.add(Dropout(0.25))
model.add(LSTM(32))
model.add(Dropout(0.25))
model.add(Dense(1, activation="sigmoid"))
model.summary()   # 顯示模型摘要資訊
# 編譯模型
model.compile(loss="binary_crossentropy", optimizer="rmsprop", 
              metrics=["accuracy"])
# 訓練模型
history = model.fit(X_train, Y_train, validation_split=0.2, epochs=20, batch_size=128, verbose=0)
# 評估模型
loss, accuracy = model.evaluate(X_test, Y_test)
print("測試資料集的準確度 = {:.2f}".format(accuracy))

# 顯示訓練和驗證損失圖表
loss = history.history["loss"]
epochs = range(1, len(loss)+1)
val_loss = history.history["val_loss"]
plt.plot(epochs, loss, "bo", label="Training Loss")
plt.plot(epochs, val_loss, "r", label="Validation Loss")
plt.title("Training and Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()
# 顯示訓練和驗證準確度
acc = history.history["accuracy"]
epochs = range(1, len(acc)+1)
val_acc = history.history["val_accuracy"]
plt.plot(epochs, acc, "b-", label="Training Acc")
plt.plot(epochs, val_acc, "r--", label="Validation Acc")
plt.title("Training and Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()